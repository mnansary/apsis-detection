{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fde4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coreLib.dataset import DataSet\n",
    "from coreLib.utils import create_dir,LOG_INFO\n",
    "data_dir= \"/media/ansary/DriveData/Work/bengalAI/datasets/CraftData/source\"\n",
    "save_dir       = \"/media/ansary/DriveData/Work/bengalAI/datasets/CraftData/\"\n",
    "\n",
    "#save_dir       = \"/home/apsisdev/ansary/DATASETS/DETNEW\"\n",
    "#data_dir       = \"/home/apsisdev/ansary/DATASETS/synthdata_source\"\n",
    "\n",
    "ds=DataSet(data_dir)\n",
    "\n",
    "\n",
    "# #create dirs\n",
    "save_dir   =  create_dir(save_dir,\"bangla_short\")\n",
    "imgs_dir   =  create_dir(save_dir,\"imgs\")\n",
    "charmap_dir  =  create_dir(save_dir,\"charmaps\")\n",
    "wordmap_dir  =  create_dir(save_dir,\"wordmaps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coreLib.config import config\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.min_num_lines=10\n",
    "config.max_num_lines=40\n",
    "config.comp_dim=20\n",
    "config.min_line_height=4\n",
    "config.word_min_space=5\n",
    "config.word_max_space=10\n",
    "config.vert_max_space=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04294c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coreLib.render_short import createSceneImage,backgroundGenerator,createImageData\n",
    "from coreLib.word_short import create_word\n",
    "backGen=backgroundGenerator(ds,dim=(config.back_dim,config.back_dim))\n",
    "back=next(backGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fb582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------\n",
    "# imports\n",
    "#--------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#--------------------\n",
    "# format\n",
    "#--------------------\n",
    "\n",
    "def get_gaussian_heatmap(size=512, distanceRatio=1.5):\n",
    "    '''\n",
    "        creates a gaussian heatmap\n",
    "        This is a fixed operation to create heatmaps\n",
    "    '''\n",
    "    # distrivute values\n",
    "    v = np.abs(np.linspace(-size / 2, size / 2, num=size))\n",
    "    # create a value mesh grid\n",
    "    x, y = np.meshgrid(v, v)\n",
    "    # spreading heatmap\n",
    "    g = np.sqrt(x**2 + y**2)\n",
    "    g *= distanceRatio / (size / 2)\n",
    "    g = np.exp(-(1 / 2) * (g**2))\n",
    "    g *= 255\n",
    "    return g.clip(0, 255).astype('uint8')\n",
    "\n",
    "heatmap=get_gaussian_heatmap(size=1024,distanceRatio=2)\n",
    "\n",
    "\n",
    "def get_targets(page,labels):\n",
    "    '''\n",
    "        @author\n",
    "        create a function to convert page image to total text format data\n",
    "        This should not depend on- \n",
    "            * language or \n",
    "            * type (handwritten/printed) or \n",
    "            * data(number/word/symbol)\n",
    "        args:\n",
    "            page   :     marked image of a page given at letter by letter \n",
    "            labels :     list of markings for each word\n",
    "        returns:\n",
    "            whatever is necessary for the total-text format\n",
    "         \n",
    "    '''\n",
    "    # source bbobx of heatmap\n",
    "    src = np.array([[0, 0], \n",
    "                    [heatmap.shape[1], 0], \n",
    "                    [heatmap.shape[1], heatmap.shape[0]],\n",
    "                    [0, heatmap.shape[0]]]).astype('float32')\n",
    "\n",
    "    # word_mask\n",
    "    word_mask=np.zeros(page.shape)\n",
    "    # char mask\n",
    "    char_mask=np.zeros(page.shape)\n",
    "    for line_labels in labels:\n",
    "        for label in line_labels:\n",
    "            for k,v in label.items():\n",
    "                if v!=' ':\n",
    "                    char_mask[page==k]=255\n",
    "                    idx = np.where(page==k)\n",
    "                    \n",
    "                    y_min,y_max,x_min,x_max = np.min(idx[0]), np.max(idx[0]), np.min(idx[1]), np.max(idx[1])\n",
    "                    x1=x_min\n",
    "                    y1=y_max\n",
    "                    x2=x_max\n",
    "                    y2=y_max\n",
    "                    x3=x_max\n",
    "                    y3=y_min\n",
    "                    x4=x_min\n",
    "                    y4=y_min\n",
    "                    word_points = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]]).astype('float32') \n",
    "                    # transforms the bbox and creates the heatmap\n",
    "                    M = cv2.getPerspectiveTransform(src=src,dst=word_points)\n",
    "                    word_mask+= cv2.warpPerspective(heatmap,\n",
    "                                                    M, \n",
    "                                                    dsize=(word_mask.shape[1],\n",
    "                                                           word_mask.shape[0])).astype('float32')\n",
    "\n",
    "    char_mask=char_mask.astype(\"uint8\")\n",
    "    word_mask=word_mask.astype(\"uint8\")\n",
    "    return char_mask,word_mask\n",
    "#     #return char_mask#,word_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da31bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def saveData(nb):\n",
    "    '''\n",
    "        number of images to save\n",
    "    '''\n",
    "    for i in tqdm(range(nb)):\n",
    "        try:\n",
    "            # data execution\n",
    "            page,labels=createSceneImage(ds)\n",
    "            back=createImageData(backGen,page,labels)\n",
    "            charmap,wordmap=get_targets(page,labels)\n",
    "            # data formation\n",
    "            img_path =os.path.join(imgs_dir,f\"img{i}.png\")\n",
    "            char_path=os.path.join(charmap_dir,f\"img{i}.png\")\n",
    "            word_path=os.path.join(wordmap_dir,f\"img{i}.png\")\n",
    "            # save\n",
    "            cv2.imwrite(img_path,cv2.resize(back,(256,256)))\n",
    "            cv2.imwrite(char_path,cv2.resize(charmap,(256,256)))\n",
    "            cv2.imwrite(word_path,cv2.resize(wordmap,(256,256)))\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff740ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "bangla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
